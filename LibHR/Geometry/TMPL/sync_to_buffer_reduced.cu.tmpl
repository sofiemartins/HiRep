/***************************************************************************\
* Copyright (c) 2023, Sofie Martins                                         *   
* All rights reserved.                                                      * 
\***************************************************************************/

#include "Utils/generics.h"
#include "libhr_core.h"

#if !defined _FIELD_TYPE
#error Missing _FIELD_TYPE in sync_to_buffer_reduced.cu
#endif
#if !defined _SITE_TYPE
#error Missing _SITE_TYPE in sync_to_buffer_reduced.cu
#endif
#if !defined _GAUGE_TYPE
#error Missing _GAUGE_TYPE in sync_to_buffer_reduced.cu
#endif
#if !defined _HSPINOR_TYPE
#error Missing _SITE_TYPE in sync_to_buffer_reduced.cu
#endif
#if !defined _FIELD_DIM
#error Missing _FIELD_DIM in sync_to_buffer_reduced.cu
#endif
#if !defined _REP_SUFFIX
#error missing _REP_SUFFIX in sync_to_buffer_reduced.cu
#endif

#define _KERNEL(_name, _args) __global__ _FUNC(void, _name, _FIELD_TYPE, _args)
#define _DECLARE(_type, _name, _args) _FUNC(_type, _name, _FIELD_TYPE, _args)

#define GFIELD(_gauge, _suffix) CONCAT(_gauge, _suffix)

_KERNEL(box_to_buffer_kernel_reduced_,
        (_GAUGE_TYPE * gauge, void *field_out, _SITE_TYPE *in, int base_out_even, int base_out_odd, int vol_out_even,
         int vol_out_odd, int gd_in, int *idn_gpu, coord4 *icoord, int *ipt_gpu, char mask)) {
    const int base_out[2] = { base_out_even, base_out_odd };
    const int vol_out[2] = { vol_out_even, vol_out_odd };
    _KERNEL_PIECE_FOR(piece) {
        _IF_IN_BOX_OUT2(gd_in, vol_out, piece) {
            int ix = blockIdx.x * blockDim.x + threadIdx.x;
            coord4 c = icoord[ix + base_out[piece - 1]];
            int iy = ipt_ext_gpu(c.x[0], c.x[1], c.x[2], c.x[3]);
            _GAUGE_TYPE u;
            _HSPINOR_TYPE r, sn;
            _HSPINOR_TYPE *out = (_HSPINOR_TYPE *)((_SITE_TYPE *)field_out + base_out[piece - 1]);

            if (mask & T_UP_MASK) {
                int ixg = idn_gpu[4 * iy];
                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 0);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 2);
                read_gpu<_REAL>(0, &u, gauge, ixg, 0, 4);

                _vector_add_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_T_multiply(sn.c[1], u, sn.c[0]);

                r.c[0] = sn.c[1];

                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 1);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 3);

                _vector_add_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_T_multiply(sn.c[1], u, sn.c[0]);

                r.c[1] = sn.c[1];
                write_gpu<_REAL>(0, &r, out, ix, 0, _FIELD_DIM);
            }

            if (mask & T_DN_MASK) {
                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 0);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 2);
                read_gpu<_REAL>(0, &u, gauge, iy, 0, 4);

                _vector_sub_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_T_inverse_multiply(sn.c[1], u, sn.c[0]);

                r.c[0] = sn.c[1];

                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 1);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 3);

                _vector_sub_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_T_inverse_multiply(sn.c[1], u, sn.c[0]);

                r.c[1] = sn.c[1];
                write_gpu<_REAL>(0, &r, out, ix, 0, _FIELD_DIM);
            }

            if (mask & X_UP_MASK) {
                int ixg = idn_gpu[4 * iy + 1];
                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 0);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 3);
                read_gpu<_REAL>(0, &u, gauge, ixg, 1, 4);

                _vector_i_add_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_X_multiply(sn.c[1], u, sn.c[0]);

                r.c[0] = sn.c[1];

                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 1);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 2);

                _vector_i_add_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_X_multiply(sn.c[1], u, sn.c[0]);

                r.c[1] = sn.c[1];
                write_gpu<_REAL>(0, &r, out, ix, 0, _FIELD_DIM);
            }

            if (mask & X_DN_MASK) {
                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 0);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 3);
                read_gpu<_REAL>(0, &u, gauge, iy, 1, 4);

                _vector_i_sub_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_X_inverse_multiply(sn.c[1], u, sn.c[0]);

                r.c[0] = sn.c[1];

                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 1);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 2);

                _vector_i_sub_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_X_inverse_multiply(sn.c[1], u, sn.c[0]);

                r.c[1] = sn.c[1];
                write_gpu<_REAL>(0, &r, out, ix, 0, _FIELD_DIM);
            }

            if (mask & Y_UP_MASK) {
                int ixg = idn_gpu[4 * iy + 2];
                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 0);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 3);
                read_gpu<_REAL>(0, &u, gauge, ixg, 2, 4);

                _vector_add_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_Y_multiply(sn.c[1], u, sn.c[0]);

                r.c[0] = sn.c[1];

                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 1);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 2);

                _vector_sub_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_Y_multiply(sn.c[1], u, sn.c[0]);

                r.c[1] = sn.c[1];
                write_gpu<_REAL>(0, &r, out, ix, 0, _FIELD_DIM);
            }

            if (mask & Y_DN_MASK) {
                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 0);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 3);
                read_gpu<_REAL>(0, &u, gauge, iy, 2, 4);

                _vector_sub_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_Y_inverse_multiply(sn.c[1], u, sn.c[0]);

                r.c[0] = sn.c[1];

                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 1);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 2);

                _vector_add_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_Y_inverse_multiply(sn.c[1], u, sn.c[0]);

                r.c[1] = sn.c[1];
                write_gpu<_REAL>(0, &r, out, ix, 0, _FIELD_DIM);
            }

            if (mask & Z_UP_MASK) {
                int ixg = idn_gpu[4 * iy + 3];
                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 0);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 2);
                read_gpu<_REAL>(0, &u, gauge, ixg, 3, 4);

                _vector_i_add_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_Z_multiply(sn.c[1], u, sn.c[0]);

                r.c[0] = sn.c[1];

                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 1);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 3);
                _vector_i_sub_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_Z_multiply(sn.c[1], u, sn.c[0]);

                r.c[1] = sn.c[1];
                write_gpu<_REAL>(0, &r, out, ix, 0, _FIELD_DIM);
            }

            if (mask & Z_DN_MASK) {
                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 0);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 2);
                read_gpu<_REAL>(0, &u, gauge, iy, 3, 4);

                _vector_i_sub_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_Z_inverse_multiply(sn.c[1], u, sn.c[0]);

                r.c[0] = sn.c[1];

                in_spinor_field<_REAL>(&(sn.c[0]), in, iy, 1);
                in_spinor_field<_REAL>(&(sn.c[1]), in, iy, 3);

                _vector_i_add_assign_f(sn.c[0], sn.c[1]);
                _suNf_theta_Z_inverse_multiply(sn.c[1], u, sn.c[0]);

                r.c[1] = sn.c[1];
                write_gpu<_REAL>(0, &r, out, ix, 0, _FIELD_DIM);
            }
        }
    }
}

_DECLARE(void, sync_box_to_buffer_gpu_reduced_,
         (geometry_descriptor * gd, box_t *src, _FIELD_TYPE *in, void *sendbuf, int buf, char mask)) {
    enum gd_type gd_t = GLOBAL;
    if (gd == &glat_even) { gd_t = EVEN; }
    if (gd == &glat_odd) { gd_t = ODD; }
    const int max_vol = fmax(boxEvenVolume(src), boxOddVolume(src));
    const int grid = (max_vol - 1) / BLOCK_SIZE + 1;
    _F_NAME(box_to_buffer_kernel_reduced_, _FIELD_TYPE)<<<grid, BLOCK_SIZE, 0, sync_stream[buf % 8]>>>(
        GFIELD(u_gauge, _REP_SUFFIX)->gpu_ptr, sendbuf, in->gpu_ptr - in->type->master_shift, src->base_index,
        src->base_index_odd, boxEvenVolume(src), boxOddVolume(src), gd_t, idn_gpu, sb_icoord_gpu, ipt_gpu, mask);
}

#undef _DECLARE
#undef _KERNEL

#undef _FIELD_TYPE
#undef _SITE_TYPE
#undef _GAUGE_TYPE
#undef _HSPINOR_TYPE
#undef _FIELD_DIM
#undef _GEOM_TYPE
#undef _COMPLEX
#undef _REAL
#undef _REP_SUFFIX